services:
  dbt:
    build: .
    container_name: pycon25-dbt
    working_dir: /app
    volumes:
      - ./:/app
      - ./data:/data
    environment:
      DBT_PROFILES_DIR: /app/profiles
      SPARK_MASTER: spark://spark-master:7077
    depends_on:
      - spark-thrift
    command: ["sleep", "infinity"]
    networks:
      - spark-network

  spark-master:
    image: apache/spark:3.5.0
    container_name: pycon25-spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./data:/data
    networks:
      - spark-network

  spark-worker:
    image: apache/spark:3.5.0
    container_name: pycon25-spark-worker
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_WEBUI_PORT=8081
    ports:
      - "8081:8081"
    volumes:
      - ./data:/data
    networks:
      - spark-network

  spark-thrift:
    image: apache/spark:3.5.0
    container_name: pycon25-spark-thrift
    depends_on:
      - spark-master
      - spark-worker
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_SQL_WAREHOUSE_DIR=/data/warehouse
    command: >
      /bin/bash -c "
      mkdir -p /data/warehouse &&
      chmod -R 777 /data/warehouse 2>/dev/null || true &&
      /opt/spark/sbin/start-thriftserver.sh
      --master spark://spark-master:7077
      --conf spark.sql.warehouse.dir=/data/warehouse
      --conf spark.sql.sources.partitionOverwriteMode=dynamic
      --conf hive.exec.dynamic.partition.mode=nonstrict &&
      tail -f /opt/spark/logs/*
      "
    ports:
      - "10000:10000"
      - "4040:4040"
    volumes:
      - ./data:/data
    networks:
      - spark-network

  sqlpad:
    image: sqlpad/sqlpad:7.5.7
    container_name: pycon25-sqlpad
    depends_on:
      - spark-thrift
    ports:
      - "3000:3000"
    environment:
      SQLPAD_ADMIN: admin@example.com
      SQLPAD_ADMIN_PASSWORD: changeme
      SQLPAD_APP_LOG_LEVEL: info
      SQLPAD_WEB_LOG_LEVEL: warn
    volumes:
      - ./data:/data
      - sqlpad-data:/var/lib/sqlpad
    restart: unless-stopped
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge

volumes:
  sqlpad-data:
